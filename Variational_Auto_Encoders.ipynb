{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Variational_Auto_Encoders.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyN1F+XItNFHyyEGAUAvKc+C",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/adewoleopeyemi/Variational-Autoencoder/blob/master/Variational_Auto_Encoders.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XYnqSRlVVwat",
        "colab_type": "code",
        "outputId": "4708f729-709f-463a-82cd-393d37574a0a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#Importing import libraries\n",
        "import keras \n",
        "from keras import layers\n",
        "from keras import backend as k\n",
        "from keras.models import Model\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "img_shape = (28, 28, 1)\n",
        "batch_size = 16\n",
        "#Dimeansionality of the latent space a 2D plane\n",
        "latent_dim = 2\n",
        "\n",
        "input_img = keras.Input(shape = img_shape)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9XJa5_m-3OKU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x = layers.Conv2D(32, 3, padding = \"same\", activation = \"relu\")(input_img)\n",
        "x = layers.Conv2D(64, 3, padding = \"same\", activation = \"relu\", strides = (2, 2))(x)\n",
        "x = layers.Conv2D(64, 3, padding = \"same\", activation = \"relu\")(x)\n",
        "x = layers.Conv2D(64, 3, padding = \"same\", activation = \"relu\")(x)\n",
        "shape_before_flattening = k.int_shape(x)\n",
        "\n",
        "x = layers.Flatten()(x)\n",
        "x = layers.Dense(32, activation = \"relu\")(x)\n",
        "\n",
        "#The input image ends up being encoded into these two parameters\n",
        "z_mean = layers.Dense(latent_dim)(x)\n",
        "z_log_var = layers.Dense(latent_dim)(x) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TdQgiTRY6UgV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def sampling(args):\n",
        "  z_mean, z_log_var = args\n",
        "  epsilon = k.random_normal(shape = (k.shape(z_mean)[0], latent_dim), mean = 0., stddev = 1.)\n",
        "\n",
        "  return z_mean + k.exp(z_log_var) * epsilon\n",
        "z = layers.Lambda(sampling)([z_mean, z_log_var])\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x5Ok8nWD7d_0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "decoder_input = layers.Input(k.int_shape(z)[1:])\n",
        "\n",
        "#upsamples the input\n",
        "x = layers.Dense(np.prod(shape_before_flattening[1:]), activation = \"relu\")(decoder_input)\n",
        "\n",
        "#Reshapes z into a feature map of the same shape as the feature map just\n",
        "#before the last Flatten layer in the encoder model\n",
        "x = layers.Reshape(shape_before_flattening[1:])(x)\n",
        "\n",
        "#Uses a Conv2DTranspose layer and Conv2D layer to decode z into a feature map\n",
        "#the same size as the orignal image input\n",
        "x = layers.Conv2DTranspose(32, 3, padding = \"same\", activation = \"relu\", strides = (2, 2))(x)\n",
        "\n",
        "\n",
        "x = layers.Conv2D(1, 3,padding = \"same\", activation =\"sigmoid\")(x)\n",
        "\n",
        "decoder = Model(decoder_input, x)\n",
        "\n",
        "z_decoded = decoder(z)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R-0HOXEm-F2z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class CustomVariationalLayer(keras.layers.Layer):\n",
        "  def vae_loss(self, x, z_decoded):\n",
        "    x = k.flatten(x)\n",
        "    z_decoded = k.flatten(z_decoded)\n",
        "    xent_loss = keras.metrics.binary_crossentropy(x, z_decoded)\n",
        "    k1_loss = -5e-4 * k.mean(1 + z_log_var - k.square(z_mean) - k.exp(z_log_var), axis = -1)\n",
        "    return k.mean(xent_loss + k1_loss)\n",
        "\n",
        "  def call(self, inputs):\n",
        "    x = inputs[0]\n",
        "    z_decoded = inputs[1]\n",
        "    loss = self.vae_loss(x, z_decoded)\n",
        "    self.add_loss(loss, inputs = inputs)\n",
        "    return x\n",
        "\n",
        "y = CustomVariationalLayer()([input_img, z_decoded])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d5jwEkWUWW6h",
        "colab_type": "code",
        "outputId": "f5063129-9e6a-41c3-e386-1b5a488db334",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 649
        }
      },
      "source": [
        "from keras.datasets import mnist\n",
        "vae = Model(input_img, y)\n",
        "vae.compile(optimizer = \"rmsprop\", loss = None)\n",
        "vae.summary()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_2\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            (None, 28, 28, 1)    0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1 (Conv2D)               (None, 28, 28, 32)   320         input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_2 (Conv2D)               (None, 14, 14, 64)   18496       conv2d_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_3 (Conv2D)               (None, 14, 14, 64)   36928       conv2d_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_4 (Conv2D)               (None, 14, 14, 64)   36928       conv2d_3[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "flatten_1 (Flatten)             (None, 12544)        0           conv2d_4[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 32)           401440      flatten_1[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dense_2 (Dense)                 (None, 2)            66          dense_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_3 (Dense)                 (None, 2)            66          dense_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "lambda_1 (Lambda)               (None, 2)            0           dense_2[0][0]                    \n",
            "                                                                 dense_3[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "model_1 (Model)                 (None, 28, 28, 1)    56385       lambda_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "custom_variational_layer_1 (Cus [(None, 28, 28, 1),  0           input_1[0][0]                    \n",
            "                                                                 model_1[1][0]                    \n",
            "==================================================================================================\n",
            "Total params: 550,629\n",
            "Trainable params: 550,629\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/keras/engine/training_utils.py:819: UserWarning: Output custom_variational_layer_1 missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to custom_variational_layer_1.\n",
            "  'be expecting any data to be passed to {0}.'.format(name))\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YNzXdxs4XGM2",
        "colab_type": "code",
        "outputId": "a59a3e8f-e208-441e-f8c6-1441d2801be2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 425
        }
      },
      "source": [
        "(x_train, _), (x_test, y_test)  = mnist.load_data()\n",
        "\n",
        "x_train = x_train.astype(\"float32\") / 255.\n",
        "x_train = x_train.reshape(x_train.shape + (1,))\n",
        "\n",
        "x_test = x_test.astype(\"float32\")/255.\n",
        "x_test = x_test.reshape(x_test.shape + (1,))\n",
        "\n",
        "vae.fit(x = x_train, y = None, shuffle = True, epochs = 10, batch_size = 128, validation_data = (x_test, None))\n"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://s3.amazonaws.com/img-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 2s 0us/step\n",
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/10\n",
            "60000/60000 [==============================] - 14s 233us/step - loss: 48.0659 - val_loss: 0.2212\n",
            "Epoch 2/10\n",
            "60000/60000 [==============================] - 7s 111us/step - loss: 0.2148 - val_loss: 0.2135\n",
            "Epoch 3/10\n",
            "60000/60000 [==============================] - 7s 111us/step - loss: 0.2066 - val_loss: 0.2047\n",
            "Epoch 4/10\n",
            "60000/60000 [==============================] - 7s 111us/step - loss: 0.2010 - val_loss: 0.1972\n",
            "Epoch 5/10\n",
            "60000/60000 [==============================] - 7s 111us/step - loss: 0.1974 - val_loss: 0.1958\n",
            "Epoch 6/10\n",
            "60000/60000 [==============================] - 7s 111us/step - loss: 0.1949 - val_loss: 0.1923\n",
            "Epoch 7/10\n",
            "60000/60000 [==============================] - 7s 111us/step - loss: 0.1930 - val_loss: 0.1931\n",
            "Epoch 8/10\n",
            "60000/60000 [==============================] - 7s 111us/step - loss: 0.1915 - val_loss: 0.1904\n",
            "Epoch 9/10\n",
            "60000/60000 [==============================] - 7s 111us/step - loss: 0.1902 - val_loss: 0.1890\n",
            "Epoch 10/10\n",
            "60000/60000 [==============================] - 7s 112us/step - loss: 0.1891 - val_loss: 0.1875\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.callbacks.History at 0x7f24503414a8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BkOOoPR6YUyt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#visualization of images generated from latent space\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.stats import norm\n",
        "\n",
        "#To display a 15 * 15 \n",
        "n = 15\n",
        "digit_size = 28\n",
        "figure = np.zeros((digit_size * n, digit_size * n))\n",
        "grid_x = norm.ppf(np.linspace(0.05, 0.95, n))\n",
        "grid_y = norm.ppf(np.linspace(0.05, 0.95, n))\n",
        "\n",
        "for i, yi in enumerate(grid_x):\n",
        "  for j, xi in enumerate(grid_y):\n",
        "    z_sample = np.array([xi, yi])\n",
        "    z_sample = np.tile(z_sample, batch_size).reshape(batch_size, 2)\n",
        "    x_decoded = decoder.predict"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u06VDhCpNULA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}